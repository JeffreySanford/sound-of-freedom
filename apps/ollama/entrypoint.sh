#!/usr/bin/env bash

echo "Ollama container placeholder started"
# Here you would typically run the Ollama binary or start a process that runs the LLM server.
# Example (commented since the binary may not be present):
# /opt/ollama/bin/ollama serve --model <model> --port 11434

# Fallback to sleep loop for the placeholder container
while true; do sleep 3600; done
